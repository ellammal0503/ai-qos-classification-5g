# Evaluation and Results

## 1. Metrics Used
- Accuracy  
- Precision  
- Recall  
- F1-score  

## 2. Confusion Matrix
<img width="600" height="400" alt="confusion_matrix_bilstm" src="https://github.com/user-attachments/assets/8dfc29e3-66e0-4190-aee0-8764b0c81c83" />


## 3. ROC and AUC
<img width="600" height="400" alt="roc_bilstm" src="https://github.com/user-attachments/assets/4dc288b0-29b3-4cc9-8c3a-65fa9d92e8e9" />


## 4. Results Summary
| Model        | Accuracy | Precision | Recall | F1-score | AUC |
|--------------|----------|-----------|--------|----------|-----|
| RandomForest |          |           |        |          |     |
| SVM          |          |           |        |          |     |
| KNN          |          |           |        |          |     |
| LSTM         |          |           |        |          |     |
| BiLSTM       |          |           |        |          |     |

## 5. Key Insights
- Which model performs best  
- Trade-offs between ML vs DL approaches  

